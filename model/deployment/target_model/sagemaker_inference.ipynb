{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b608a843-cc31-46e0-96a7-8af61b83be11",
   "metadata": {},
   "source": [
    "# Sagemaker Inference Custom Model\n",
    "- https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#bring-your-own-model\n",
    "- Steps:\n",
    "    - Write inference.py script\n",
    "    - Create model.tar.gz file and upload to s3\n",
    "    - Deploy\n",
    "    - Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71744de3-1349-40d0-ba8d-b53ad9876819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from pprint import pprint\n",
    "\n",
    "from sagemaker import Session\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import BytesDeserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09fcf9e-142d-4182-b755-f01b381018fa",
   "metadata": {},
   "source": [
    "## inference.py script\n",
    "\n",
    "- example: https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-python-sdk/pytorch_batch_inference/code/inference.py\n",
    "- requires model_fn, input_fn, predict_fn, output_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f88fde4-f4db-40f0-b463-440481468ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ORIGINAL FUNCTIONS\n",
    "class QNetworkWithUserEmbedding(nn.Module):\n",
    "    def __init__(self, num_game_types, num_state_variables, num_actions,\n",
    "                 user_embedding_dim=4, game_embedding_dim=1):\n",
    "        super(QNetworkWithUserEmbedding, self).__init__()\n",
    "\n",
    "        # Game type embedding\n",
    "        self.game_embedding = nn.Embedding(num_game_types, game_embedding_dim)\n",
    "\n",
    "        # Combined input: state + user embedding + game type embedding\n",
    "        input_dim = num_state_variables + user_embedding_dim + game_embedding_dim\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_actions)\n",
    "\n",
    "    def forward(self, state, user_features, game_type):\n",
    "        # No embedding on user_features â€” already embedded\n",
    "        game_embedded = self.game_embedding(game_type)  # (batch, game_embedding_dim)\n",
    "\n",
    "        x = torch.cat([state, user_features, game_embedded], dim=-1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        q_values = self.fc3(x)\n",
    "        return q_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f16b46-4c94-4ee5-a572-2c51c93068f1",
   "metadata": {},
   "source": [
    "### Model_fn\n",
    "- loads pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca66f07-2b53-4d2b-bce4-0dfa1c9a1b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(model_dir):\n",
    "    print(\"Loading Model\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    game_types_dim = 3\n",
    "    state_dim = 8\n",
    "    actions_dim = 3\n",
    "\n",
    "    # model.pt copied from primary_model_Mar_31.pt in neurobeacon/tst\n",
    "    model = QNetworkWithUserEmbedding(game_types_dim, state_dim, actions_dim)\n",
    "    with open(os.path.join(model_dir, \"model.pt\"), \"rb\") as f:\n",
    "        model.load_state_dict(torch.load(f, weights_only=False)) # remove weights_only in inference.py file\n",
    "\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffced612-4d83-4f57-ad5d-a8bf9cd2f60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QNetworkWithUserEmbedding(\n",
       "  (game_embedding): Embedding(3, 1)\n",
       "  (fc1): Linear(in_features=13, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = '/mnt/custom-file-systems/efs/fs-0f1695f072f1574e9_fsap-0f954f29efd01f1c2/model/full_model_deployment/model'\n",
    "model = model_fn(model_dir)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0341b90e-4108-4b48-86a4-887a431f3d62",
   "metadata": {},
   "source": [
    "### Input_fn\n",
    "- takes input from front end and transforms into tensor to work with predict_fn\n",
    "- serialize_to_json mimics expected serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bf28503-09de-41d1-bf3d-830509373ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: tensor([1.0000e+00, 8.7658e-03, 6.8063e-03, 6.6000e-01, 1.0000e+00, 3.1035e-04,\n",
      "        0.0000e+00, 6.2088e-01])\n",
      "action: tensor(0)\n",
      "reward: tensor(1.)\n",
      "user embedding: tensor([-1,  0,  0,  0])\n",
      "game embedding: tensor(0)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "dataset = torch.load('test_dataset_mini_embeddings.pt', weights_only=False)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "states, actions, rewards, users, games = next(iter(dataloader))\n",
    "\n",
    "idx = 0\n",
    "print('state:', states[idx])\n",
    "print('action:', actions[idx])\n",
    "print('reward:', rewards[idx])\n",
    "print('user embedding:', users[idx])\n",
    "print('game embedding:', games[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c17d78b-8fd0-4c89-9d93-0360be025362",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserEmbeddingModel(nn.Module):\n",
    "    def __init__(self, input_size, embedding_dim):\n",
    "        super(UserEmbeddingModel, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d87b0785-475e-488e-8d22-402fcbed82d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(input_state, request_content_type=\"application/json\"):\n",
    "    print(\"Input received:\", input_state)\n",
    "    input_data = json.loads(input_state)\n",
    "\n",
    "    state = input_data['states']\n",
    "    user_features = input_data['user_features']\n",
    "    game_type = input_data['game_type']\n",
    "\n",
    "    return (state, user_features, game_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eff8abf-3360-4e8c-bde0-c8be8d5e3502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('{\"states\": [1.0, 1.2326, 1.2433, 0.875, 0.78, 0.8413, 1.0, 0.9002], '\n",
      " '\"user_features\": [0.99, 0.8, 0.7], \"game_type\": 2}')\n"
     ]
    }
   ],
   "source": [
    "def serialize_to_json(data):\n",
    "    return json.dumps(data)\n",
    "    \n",
    "input_state = [1.0000, 1.2326, 1.2433, 0.8750, 0.7800, 0.8413, 1.0000, 0.9002]\n",
    "user_embedding = [0.99, 0.80, 0.70]\n",
    "game_type = 2\n",
    "\n",
    "input_dict = {\n",
    "    \"states\": input_state,\n",
    "    \"user_features\": user_embedding,\n",
    "    \"game_type\": game_type\n",
    "}\n",
    "input_json = serialize_to_json(input_dict)\n",
    "pprint(input_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9eb99230-6551-4ef4-932a-f0fe2bbd8fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input received: {\"states\": [1.0, 1.2326, 1.2433, 0.875, 0.78, 0.8413, 1.0, 0.9002], \"user_features\": [0.99, 0.8, 0.7], \"game_type\": 2}\n",
      "State: [1.0, 1.2326, 1.2433, 0.875, 0.78, 0.8413, 1.0, 0.9002]\n",
      "User Embedding: [0.99, 0.8, 0.7]\n",
      "Game Type: 2\n"
     ]
    }
   ],
   "source": [
    "state, user_features, game_type = input_fn(input_json)\n",
    "print(f\"State: {state}\")\n",
    "print(f\"User Embedding: {user_features}\")\n",
    "print(f\"Game Type: {game_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31947c5a-b6cb-433e-8be2-5549fc03abc6",
   "metadata": {},
   "source": [
    "### Predict_fn\n",
    "- takes tensor from input_fn and makes prediction\n",
    "- outputs tensor for output_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89315643-76a5-4054-969d-7041e2cf6c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(state_tuple, model):\n",
    "    \"\"\"\n",
    "    Return\n",
    "        tensor compabitable with output_fn\n",
    "    \"\"\"\n",
    "    print(\"Predict\")\n",
    "    input_size = 3\n",
    "    embedding_dim = 4\n",
    "    model_user_embed = UserEmbeddingModel(input_size, embedding_dim)\n",
    "\n",
    "    state = torch.tensor(state_tuple[0], dtype=torch.float32)\n",
    "    user_tensor = torch.tensor(state_tuple[1], dtype=torch.float32)\n",
    "    user_embedding = model_user_embed(user_tensor)\n",
    "    game_type = torch.tensor(state_tuple[2], dtype=torch.long)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        q_prediction = model(state, user_embedding, game_type)\n",
    "\n",
    "    print(\"Q_prediction:\", q_prediction)\n",
    "    print(\"Prediction:\", q_prediction.argmax())\n",
    "    return q_prediction.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8311a32f-771a-4cde-94ac-fecddfdcf896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input received: {\"states\": [1.0, 1.2326, 1.2433, 0.875, 0.78, 0.8413, 1.0, 0.9002], \"user_features\": [0.99, 0.8, 0.7], \"game_type\": 2}\n",
      "Input received: {\"states\": [1.0, 1.2326, 1.2433, 0.875, 0.78, 0.8413, 1.0, 0.9002], \"user_features\": [0.99, 0.8, 0.7], \"game_type\": 2}\n",
      "Predict\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_state = [1.0000, 1.2326, 1.2433, 0.8750, 0.7800, 0.8413, 1.0000, 0.9002]\n",
    "user_embedding = [0.99, 0.80, 0.70]\n",
    "game_type = 2\n",
    "\n",
    "input_dict = {\n",
    "    \"states\": input_state,\n",
    "    \"user_features\": user_embedding,\n",
    "    \"game_type\": game_type\n",
    "}\n",
    "input_json = serialize_to_json(input_dict)\n",
    "state, user_embedding, game_type = input_fn(input_json)\n",
    "\n",
    "predict_fn(input_fn(input_json), model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dc8f9a-2742-4884-a6f3-e085716f663c",
   "metadata": {},
   "source": [
    "### Output_fn\n",
    "- transforms tensor into output for front end application; currently returns a Byte format; can be updated to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d90bbd8-7bf4-4af3-a551-586dd78e8d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_fn(q_prediction, content_type=\"application/json\"):\n",
    "    # print(\"Prediction\", q_prediction.item())\n",
    "    if content_type == \"application/json\":\n",
    "        return json.dumps(q_prediction.item()), content_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba558d67-ab47-40db-9491-2385d6cf7b5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input received: {\"states\": [1.0, 1.2326, 1.2433, 0.875, 0.78, 0.8413, 1.0, 0.9002], \"user_features\": [0.99, 0.8, 0.7], \"game_type\": 2}\n",
      "Predict\n",
      "Prediction 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('2', 'application/json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_fn(predict_fn(input_fn(input_json), model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a013c7-b278-49e9-b78c-77b23273be5d",
   "metadata": {},
   "source": [
    "# Create and Deploy PyTorchModel\n",
    "- create model.tar.gz file with folder format:\n",
    "    - my_model/\n",
    "        - model.pth\n",
    "        - code/\n",
    "            - inference.py\n",
    "            - requirements.txt\n",
    "- deploy on specific instance (currently not serverless)\n",
    "- need to create a new endpoint and delete current endpoint to make updates to model; haven't found a way to redeploy to same endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb61a8b3-0007-4bcd-b723-2b5f61d5217a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n",
      "./.ipynb_checkpoints/\n",
      "./model.pt\n",
      "./code/\n",
      "./code/requirements.txt\n",
      "./code/.ipynb_checkpoints/\n",
      "./code/.ipynb_checkpoints/inference-checkpoint.py\n",
      "./code/inference.py\n"
     ]
    }
   ],
   "source": [
    "# create model.tar.gz file\n",
    "!tar -czvf model.tar.gz -C model ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e4421a8-9b95-42c2-8562-33f66050c4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep PyTorchModel\n",
    "role = get_execution_role()\n",
    "uri = 's3://neurobeacon/tst/models/full_model/model.tar.gz'\n",
    "pytorch_model = PyTorchModel(model_data=uri,\n",
    "                             role=role,\n",
    "                             entry_point='inference.py',\n",
    "                             py_version='py38',\n",
    "                             framework_version='1.11.0',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90ff5660-6191-42eb-b69d-b632dd0aef6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'pytorch-inference-2025-04-08-05-17-44-837'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## deploy with endpoint\n",
    "# batch inference instance price: https://aws.amazon.com/sagemaker-ai/pricing/\n",
    "# predictor = pytorch_model.deploy(instance_type='ml.c4.xlarge', initial_instance_count=1)\n",
    "predictor = pytorch_model.deploy(instance_type='ml.t2.medium', initial_instance_count=1)\n",
    "predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eab2983a-63f5-46b9-95c3-dbe48932791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint_name = 'pytorch-inference-2025-04-08-04-41-36-431'\n",
    "# sm_session = Session()\n",
    "# predictor = Predictor(\n",
    "#     endpoint_name,\n",
    "#     sm_session,\n",
    "#     serializer=JSONSerializer(),\n",
    "#     deserializer=BytesDeserializer(),\n",
    "# )\n",
    "\n",
    "# predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5f6831-f594-487a-97bf-ebca67077374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## REDEPLOY TO SAME ENDPOINT; does not work? // need to create_endpoint then shift endpoint over\n",
    "# predictor = pytorch_model.deploy(endpoint_name=predictor.endpoint_name, instance_type='ml.c4.xlarge', initial_instance_count=1, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50f7fdd-ce8c-47b3-9486-4ba6180d4edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update endpoint on front end\n",
    "# Lambda function: pytorch-inference-2025-03-09-16-32-27-874\n",
    "# FULL MODEL: pytorch-inference-2025-04-08-05-17-44-837\n",
    "# update permissions: neurobeacon_invoke_sagemaker; role: neurobeacon_sagemaker_function-role-nljcopq2 (lambda function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ed27cd-c894-4949-8933-783625b2c472",
   "metadata": {},
   "source": [
    "# Predict\n",
    "- invoke the deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21147338-cdf9-4034-9345-e3834ab73a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke deployed predictor\n",
    "def invoke(endpoint_name, sm_session, input_state):\n",
    "    predictor = Predictor(\n",
    "        endpoint_name,\n",
    "        sm_session,\n",
    "        serializer=JSONSerializer(),\n",
    "        deserializer=BytesDeserializer(),\n",
    "    )\n",
    "    return predictor.predict(input_state)\n",
    "\n",
    "def serialize_to_json(data):\n",
    "    return json.dumps(data)\n",
    "\n",
    "def input_fn(input_state, request_content_type=\"application/json\"):\n",
    "    print(\"Input received:\", input_state)\n",
    "    input_data = json.loads(input_state)\n",
    "\n",
    "    state = input_data['states']\n",
    "    user_features = input_data['user_features']\n",
    "    game_type = input_data['game_type']\n",
    "\n",
    "    return (state, user_features, game_type)\n",
    "\n",
    "class UserEmbeddingModel(nn.Module):\n",
    "    def __init__(self, input_size, embedding_dim):\n",
    "        super(UserEmbeddingModel, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "endpoint_name = 'pytorch-inference-2025-04-08-05-17-44-837'\n",
    "sm_session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b79d756-bd91-4cce-8fba-3b1a36d7a2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: tensor([1.0000e+00, 7.4509e-02, 6.1666e-02, 7.1000e-01, 8.9000e-01, 2.6761e-04,\n",
      "        1.0000e+00, 7.9671e-01])\n",
      "action: tensor(2)\n",
      "reward: tensor(3.)\n",
      "user embedding: tensor([-1,  0,  0,  0])\n",
      "game embedding: tensor(0)\n",
      "{'states': [1.0, 0.07450941205024719, 0.06166564300656319, 0.7099999785423279, 0.8899999856948853, 0.0002676145522855222, 1.0, 0.7967052459716797], 'user_features': [0.5, 0.5, 0.69], 'game_type': 2}\n",
      "Input received: {\"states\": [1.0, 1.2326, 1.2433, 0.875, 0.78, 0.8413, 1.0, 0.9002], \"user_features\": [0.99, 0.8, 0.7], \"game_type\": 2}\n",
      "([1.0, 1.2326, 1.2433, 0.875, 0.78, 0.8413, 1.0, 0.9002], [0.99, 0.8, 0.7], 2)\n"
     ]
    }
   ],
   "source": [
    "# see data\n",
    "batch_size = 32\n",
    "dataset = torch.load('test_dataset_mini_embeddings.pt', weights_only=False)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "states, actions, rewards, users, games = next(iter(dataloader))\n",
    "\n",
    "idx = 0\n",
    "print('state:', states[idx])\n",
    "print('action:', actions[idx])\n",
    "print('reward:', rewards[idx])\n",
    "print('user embedding:', users[idx])\n",
    "print('game embedding:', games[idx])\n",
    "\n",
    "idx = 0\n",
    "user_features = [0.50, 0.50, 0.69]\n",
    "input_dictionary = {\n",
    "    \"states\": states[idx].tolist(),\n",
    "    \"user_features\": user_features,\n",
    "    \"game_type\": 2\n",
    "}\n",
    "print(input_dictionary)\n",
    "\n",
    "input_state = input_fn(input_json)\n",
    "print(input_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5d45c23-9069-4d84-9e12-7d49a3413af3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: b'2'\n"
     ]
    }
   ],
   "source": [
    "results = invoke(endpoint_name, sm_session, input_dictionary)\n",
    "print('Prediction:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adb535ed-3ba3-4892-8b20-863eba807548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input State: [1.         1.17476852 1.18456376 0.8625     0.81       0.79556463\n",
      " 0.         0.90078386]\n",
      "Prediction: b'2'\n"
     ]
    }
   ],
   "source": [
    "idx = 150\n",
    "input_state = states[idx]\n",
    "print('Input State:', input_state)\n",
    "\n",
    "results = invoke(endpoint_name, sm_session)\n",
    "print('Prediction:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7923e04-1c6d-44a0-b3b1-f31a35cee77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor = Predictor(\n",
    "#     endpoint_name,\n",
    "#     sm_session,\n",
    "#     serializer=JSONSerializer(),\n",
    "#     deserializer=BytesDeserializer(),\n",
    "# )\n",
    "\n",
    "# predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
